{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe5e332-6eb5-4709-aa72-b8ec088cde11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb45bdd4-6f64-4abe-810a-654c8fdd0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13c2a83-b9c5-425b-ba76-1927b6841283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from baselines.ppo2 import ppo2\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "# from baselines import deepq  # Deep Q Network (DQN) \n",
    "# from baselines import bench  # https://github.com/openai/baselines/tree/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/bench\n",
    "# from baselines import logger\n",
    "# import tensorflow as tf\n",
    "\n",
    "from baselines.common.tf_util import make_session\n",
    "\n",
    "# import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f0e48-0277-4ac4-bdc0-99a92a5c7c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d069fed5-b018-4b39-a504-6540f3b0cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read images from a directory and return image paths and labels\n",
    "def read_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for image_file in os.listdir(label_dir):\n",
    "                image_path = os.path.join(label_dir, image_file)\n",
    "                images.append(image_path)\n",
    "                labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ed988e-215a-44df-840a-c4a265f484cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for train and test sets\n",
    "train_directory = r\"C:\\Users\\123\\Documents\\SD Labs\\Cyber\\dataset\\OCT2017\\train\"\n",
    "test_directory = r\"C:\\Users\\123\\Documents\\SD Labs\\Cyber\\dataset\\OCT2017\\test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a41bc8-51a1-4b37-bc74-fb0a43ef681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform exploratory data analysis (EDA)\n",
    "def perform_eda(images, labels):\n",
    "    # Count the number of images in each class\n",
    "    class_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    print(\"Class Counts:\", class_counts)\n",
    "\n",
    "    # Show sample images from each class\n",
    "    num_samples_per_class = 3\n",
    "    fig, axes = plt.subplots(len(class_counts), num_samples_per_class, figsize=(12, 8))\n",
    "    fig.suptitle(\"Sample Images from Each Class\", fontsize=16)\n",
    "\n",
    "    for i, (label, count) in enumerate(class_counts.items()):\n",
    "        image_paths = [img_path for img_path, img_label in zip(images, labels) if img_label == label]\n",
    "        for j in range(num_samples_per_class):\n",
    "            img = Image.open(image_paths[j])\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis(\"off\")\n",
    "            axes[i, j].set_title(f\"{label} - {os.path.basename(image_paths[j])}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ff1b6f-5d0d-4fef-9666-4a3a7124b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read train and test images along with their labels\n",
    "train_images, train_labels = read_images_from_directory(train_directory)\n",
    "test_images, test_labels = read_images_from_directory(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714e7ac6-886c-47e7-aadc-d9e86e5824fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform EDA on train set\n",
    "# perform_eda(train_images, train_labels)\n",
    "\n",
    "# Perform EDA on test set\n",
    "# perform_eda(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357e801d-ce18-41b6-ba61-87aa22b79736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/openai/baselines.git@ea25b9e8b234e6ee1bca43083f8f3cf974143998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de377796-8af5-4e3e-93d2-be37941b4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 4\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0a8b9d-89db-442d-adf4-21091c507553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Convert train_images to a numpy array\n",
    "# train_images = np.array(train_images)\n",
    "\n",
    "# # Scale images to the [0, 1] range\n",
    "# train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "# # Make sure images have shape (28, 28, 1)\n",
    "# train_images = np.expand_dims(train_images, -1)\n",
    "\n",
    "# print(\"train_images shape:\", train_images.shape)\n",
    "# print(train_images.shape[0], \"train_images samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93bf636-b91f-4380-ac1d-c62013dcf318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8348/8348 [04:57<00:00, 28.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (8348, 28, 28, 1)\n",
      "8348 train_images samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(file_paths, percent=100):\n",
    "    images = []\n",
    "    num_images = int(len(file_paths) * (percent / 100))\n",
    "    for file_path in tqdm(file_paths[:num_images]):\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((28, 28))  # Resize the image to (28, 28)\n",
    "        img = np.array(img)\n",
    "        images.append(img)\n",
    "    images = np.array(images)\n",
    "    images = images.astype(\"float32\") / 255\n",
    "    images = np.expand_dims(images, -1)\n",
    "    return images\n",
    "\n",
    "# Convert train_images and test_images to numpy arrays and preprocess them\n",
    "train_images = load_and_preprocess_images(train_images,  percent=10)\n",
    "test_images = load_and_preprocess_images(test_images,  percent=10)\n",
    "\n",
    "print(\"train_images shape:\", train_images.shape)\n",
    "print(train_images.shape[0], \"train_images samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c91efd-b47c-43d1-85b6-4bbe3603e93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4e4690-827f-4013-8b3c-705dd184a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# y_train_one_hot = keras.utils.to_categorical(test_images, num_classes)\n",
    "# y_test_one_hot = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "\n",
    "# Convert class labels to integer class indices\n",
    "class_indices = {label: index for index, label in enumerate(set(train_labels))}\n",
    "train_labels = [class_indices[label] for label in train_labels]\n",
    "test_labels = [class_indices[label] for label in test_labels]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_one_hot = keras.utils.to_categorical(train_labels, num_classes)\n",
    "y_test_one_hot = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9416c80-4e49-454e-945c-2e8252792cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def keras_train(batch_size=32, epochs=2):\n",
    "#     model = keras.Sequential(\n",
    "#         [\n",
    "#             keras.Input(shape=input_shape),\n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(num_classes, activation=\"softmax\")\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     model.fit(x_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     score = model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "#     print(\"Test loss:\", score[0])\n",
    "#     print(\"Test accuracy:\", score[1])\n",
    "#     print(\"Training Time:\", end_time - start_time)\n",
    "\n",
    "# keras_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a71081-46fc-45a8-93b5-95cf437b0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MnistEnv(gym.Env):\n",
    "#     def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.action_space = gym.spaces.Discrete(10)\n",
    "#         self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "#                                                 shape=(28, 28, 1),\n",
    "#                                                 dtype=np.float32)\n",
    "\n",
    "#         self.images_per_episode = images_per_episode\n",
    "#         self.step_count = 0\n",
    "\n",
    "#         self.x, self.y = dataset\n",
    "#         self.random = random\n",
    "#         self.dataset_idx = 0\n",
    "\n",
    "#     def step(self, action):\n",
    "#         done = False\n",
    "#         reward = int(action == self.expected_action)\n",
    "\n",
    "#         obs = self._next_obs()\n",
    "\n",
    "#         self.step_count += 1\n",
    "#         if self.step_count >= self.images_per_episode:\n",
    "#             done = True\n",
    "\n",
    "#         return obs, reward, done, {}\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.step_count = 0\n",
    "\n",
    "#         obs = self._next_obs()\n",
    "#         return obs\n",
    "\n",
    "#     def _next_obs(self):\n",
    "#         if self.random:\n",
    "#             next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "#             self.expected_action = int(self.y[next_obs_idx])\n",
    "#             obs = self.x[next_obs_idx]\n",
    "\n",
    "#         else:\n",
    "#             obs = self.x[self.dataset_idx]\n",
    "#             self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "#             self.dataset_idx += 1\n",
    "#             if self.dataset_idx >= len(self.x):\n",
    "#                 raise StopIteration()\n",
    "\n",
    "#         return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e91bcf-e494-4ea3-86b4-224b46020666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dqn():\n",
    "#     logger.configure(dir='./logs/mnist_dqn', format_strs=['stdout', 'tensorboard'])\n",
    "#     env = MnistEnv(images_per_episode=1)\n",
    "#     env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "#     model = deepq.learn(\n",
    "#         env,\n",
    "#         \"mlp\",\n",
    "#         num_layers=1,\n",
    "#         num_hidden=64,\n",
    "#         activation=tf.nn.relu,\n",
    "#         hiddens=[32],\n",
    "#         dueling=True,\n",
    "#         lr=1e-4,\n",
    "#         total_timesteps=int(1.2e5),\n",
    "#         buffer_size=10000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.01,\n",
    "#         train_freq=4,\n",
    "#         learning_starts=10000,\n",
    "#         target_network_update_freq=1000,\n",
    "#     )\n",
    "\n",
    "#     model.save('dqn_mnist.pkl')\n",
    "#     env.close()\n",
    "\n",
    "#     return model\n",
    "\n",
    "# start_time = time.time()\n",
    "# dqn_model = mnist_dqn()\n",
    "# print(\"DQN Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ceafd-d4a7-4785-9c41-259a477a642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dqn_eval(dqn_model):\n",
    "#     attempts, correct = 0,0\n",
    "\n",
    "#     env = MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             obs, done = env.reset(), False\n",
    "#             while not done:\n",
    "#                 obs, rew, done, _ = env.step(dqn_model(obs[None])[0])\n",
    "\n",
    "#                 attempts += 1\n",
    "#                 if rew > 0:\n",
    "#                     correct += 1\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print()\n",
    "#         print('validation done...')\n",
    "#         print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "# mnist_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0fa87-bcb2-4010-81f5-2f3896209b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_ppo():\n",
    "#     logger.configure(dir='./logs/mnist_ppo', format_strs=['stdout', 'tensorboard'])\n",
    "#     env = DummyVecEnv([lambda: bench.Monitor(MnistEnv(images_per_episode=1), logger.get_dir())])\n",
    "\n",
    "#     model = ppo2.learn(\n",
    "#         env=env,\n",
    "#         network='mlp',\n",
    "#         num_layers=2,\n",
    "#         num_hidden=64,\n",
    "#         nsteps=32,\n",
    "#         total_timesteps=int(1.2e5),\n",
    "#         seed=int(time.time()))\n",
    "\n",
    "#     return model\n",
    "\n",
    "# start_time = time.time()\n",
    "# ppo_model = mnist_ppo()\n",
    "# print(\"PPO Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c1250-43fa-4da5-bf51-c2ca1c584e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_ppo_eval(ppo_model):\n",
    "#     attempts, correct = 0,0\n",
    "\n",
    "#     env = DummyVecEnv([lambda: MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)])\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             obs, done = env.reset(), [False]\n",
    "#             while not done[0]:\n",
    "#                 obs, rew, done, _ = env.step(ppo_model.step(obs[None])[0])\n",
    "\n",
    "#                 attempts += 1\n",
    "#                 if rew[0] > 0:\n",
    "#                     correct += 1\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print()\n",
    "#         print('validation done...')\n",
    "#         print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "# mnist_ppo_eval(ppo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4885655-529e-4f1c-9bbd-1a6aadfb6381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925ab82-baf5-4f6c-a5ca-b8035e32dea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f42b1-2768-47d6-866b-1c7a153be042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffb317-15ed-4870-b015-a1356693c4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5eb13-3d6d-449f-8736-808d4c1c176b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e19e0-ad86-4625-8e9b-e2897a21e3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7601c-9904-4be1-9c28-2abeaf71eafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e2a88-18fc-411c-aa96-a4a2b8372659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11623f0-f1c6-40ff-bde9-a7b226dc1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31826d0c-bf06-4af7-b366-56bd3cd2197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbd57c-d89b-4f1c-86b7-591cfd8ab455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a6945-e671-4020-8ba3-9e1a55d2b40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00611bb-1a11-4771-af5c-362e3effb025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a686ba-b530-4dcb-963b-b384a301a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4017016-4e97-4fb6-b056-31f81d6d1159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a404-5d71-4b54-9bd9-33b3ab6b12a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df45aa9-9782-4ebe-bc52-0767246f9c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ac9af-f1f0-4fd5-ab45-6fc365df6a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a312b-0ffd-474e-a2e3-857314976a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa8c23-eb95-4f49-93ab-646e8bed4b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234074d8-d5db-44b7-a371-9e9b68ca106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0894e2-dfaf-45e7-8a59-6477dd246fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154de4fc-32b0-4f18-a37e-1a47df690b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fcb2d-1e1a-4b97-8882-673532a72834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40640fa7-ed33-4b31-b432-c8d94be4d9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a6359-5e52-4a87-afda-dd75a8cb9fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
