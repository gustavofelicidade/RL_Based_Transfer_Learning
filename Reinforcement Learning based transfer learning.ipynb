{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe5e332-6eb5-4709-aa72-b8ec088cde11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08280ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade \"protobuf<=3.19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb45bdd4-6f64-4abe-810a-654c8fdd0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13c2a83-b9c5-425b-ba76-1927b6841283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import gym\n",
    "# from baselines.ppo2 import ppo2\n",
    "# from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "# from baselines import deepq  # Deep Q Network (DQN) \n",
    "# from baselines import bench  # https://github.com/openai/baselines/tree/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/bench\n",
    "# from baselines import logger\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from baselines.common.tf_util import make_session\n",
    "\n",
    "# import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common import logger\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "from stable_baselines3.common.env_util import make_atari_env, make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491f0e48-0277-4ac4-bdc0-99a92a5c7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(logging.INFO)\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# ch = logging.StreamHandler()\n",
    "# ch.setLevel(logging.INFO)\n",
    "# ch.setFormatter(formatter)\n",
    "# logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d069fed5-b018-4b39-a504-6540f3b0cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read images from a directory and return image paths and labels\n",
    "def read_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for image_file in os.listdir(label_dir):\n",
    "                image_path = os.path.join(label_dir, image_file)\n",
    "                images.append(image_path)\n",
    "                labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ed988e-215a-44df-840a-c4a265f484cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for train and test sets LAPTOP\n",
    "# train_directory = r\"C:\\Users\\123\\Documents\\SD Labs\\Cyber\\dataset\\OCT2017\\train\"\n",
    "# test_directory = r\"C:\\Users\\123\\Documents\\SD Labs\\Cyber\\dataset\\OCT2017\\test\"\n",
    "\n",
    "# Directories for train and test sets Desktop\n",
    "train_directory = r\"D:\\Arquivos HD\\Projetos HD\\SD Labs\\JOBS\\Cyber Space Marketing\\dataset\\OCT2017\\train\"\n",
    "test_directory = r\"D:\\Arquivos HD\\Projetos HD\\SD Labs\\JOBS\\Cyber Space Marketing\\dataset\\OCT2017\\test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a41bc8-51a1-4b37-bc74-fb0a43ef681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform exploratory data analysis (EDA)\n",
    "def perform_eda(images, labels):\n",
    "    # Count the number of images in each class\n",
    "    class_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    print(\"Class Counts:\", class_counts)\n",
    "\n",
    "    # Show sample images from each class\n",
    "    num_samples_per_class = 3\n",
    "    fig, axes = plt.subplots(len(class_counts), num_samples_per_class, figsize=(12, 8))\n",
    "    fig.suptitle(\"Sample Images from Each Class\", fontsize=16)\n",
    "\n",
    "    for i, (label, count) in enumerate(class_counts.items()):\n",
    "        image_paths = [img_path for img_path, img_label in zip(images, labels) if img_label == label]\n",
    "        for j in range(num_samples_per_class):\n",
    "            img = Image.open(image_paths[j])\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis(\"off\")\n",
    "            axes[i, j].set_title(f\"{label} - {os.path.basename(image_paths[j])}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ff1b6f-5d0d-4fef-9666-4a3a7124b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read train and test images along with their labels\n",
    "train_images, train_labels = read_images_from_directory(train_directory)\n",
    "test_images, test_labels = read_images_from_directory(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714e7ac6-886c-47e7-aadc-d9e86e5824fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform EDA on train set\n",
    "# perform_eda(train_images, train_labels)\n",
    "\n",
    "# Perform EDA on test set\n",
    "# perform_eda(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357e801d-ce18-41b6-ba61-87aa22b79736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/openai/baselines.git@ea25b9e8b234e6ee1bca43083f8f3cf974143998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de377796-8af5-4e3e-93d2-be37941b4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 4\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0a8b9d-89db-442d-adf4-21091c507553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Convert train_images to a numpy array\n",
    "# train_images = np.array(train_images)\n",
    "\n",
    "# # Scale images to the [0, 1] range\n",
    "# train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "# # Make sure images have shape (28, 28, 1)\n",
    "# train_images = np.expand_dims(train_images, -1)\n",
    "\n",
    "# print(\"train_images shape:\", train_images.shape)\n",
    "# print(train_images.shape[0], \"train_images samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93bf636-b91f-4380-ac1d-c62013dcf318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8348/8348 [03:58<00:00, 35.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 102.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (8348, 28, 28, 1)\n",
      "8348 train_images samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(file_paths, percent=100):\n",
    "    images = []\n",
    "    num_images = int(len(file_paths) * (percent / 100))\n",
    "    for file_path in tqdm(file_paths[:num_images]):\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((28, 28))  # Resize the image to (28, 28)\n",
    "        img = np.array(img)\n",
    "        images.append(img)\n",
    "    images = np.array(images)\n",
    "    images = images.astype(\"float32\") / 255\n",
    "    images = np.expand_dims(images, -1)\n",
    "    return images\n",
    "\n",
    "# Convert train_images and test_images to numpy arrays and preprocess them\n",
    "train_images = load_and_preprocess_images(train_images,  percent=10)\n",
    "test_images = load_and_preprocess_images(test_images,  percent=10)\n",
    "\n",
    "print(\"train_images shape:\", train_images.shape)\n",
    "print(train_images.shape[0], \"train_images samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cb353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4e4690-827f-4013-8b3c-705dd184a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 83484\n",
      "<class 'list'> 1000\n",
      "<class 'numpy.ndarray'> 83484\n",
      "<class 'numpy.ndarray'> 1000\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# y_train_one_hot = keras.utils.to_categorical(test_images, num_classes)\n",
    "# y_test_one_hot = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "\n",
    "# Convert class labels to integer class indices\n",
    "class_indices = {label: index for index, label in enumerate(set(train_labels))}\n",
    "train_labels = [class_indices[label] for label in train_labels]\n",
    "test_labels = [class_indices[label] for label in test_labels]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train_one_hot = keras.utils.to_categorical(train_labels, num_classes)\n",
    "# y_test_one_hot = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "y_train_one_hot = keras.utils.to_categorical(train_labels, num_classes, dtype='float32')\n",
    "y_test_one_hot = keras.utils.to_categorical(test_labels, num_classes, dtype='float32')\n",
    "\n",
    "\n",
    "print(type(train_labels), len(train_labels)) \n",
    "print(type(test_labels), len(test_labels))\n",
    "\n",
    "# train_labels = np.array(train_labels)\n",
    "# test_labels =  np.array(test_labels)\n",
    "\n",
    "# print(type(train_labels)) \n",
    "# print(type(test_labels))\n",
    "print(type(y_train_one_hot), len(y_train_one_hot)) \n",
    "print(type(y_test_one_hot), len(y_test_one_hot)) \n",
    "# train_labels = np.array(train_labels)\n",
    "# test_labels = np.array(test_labels)\n",
    "# y_train_one_hot = np.array(y_train_one_hot)\n",
    "# y_test_one_hot = np.array(y_test_one_hot)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b407e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(83484,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels =  np.array(test_labels)\n",
    "\n",
    "print(type(train_labels)) \n",
    "print(type(test_labels))\n",
    "print(train_labels.shape) \n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9049a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def keras_train(batch_size=32, epochs=2):\n",
    "#     model = keras.Sequential(\n",
    "#         [\n",
    "#             keras.Input(shape=input_shape),\n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(num_classes, activation=\"softmax\")\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     model.fit(train_labels,\n",
    "#               y_train_one_hot,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs)\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     score = model.evaluate(test_labels, y_test_one_hot, verbose=0)\n",
    "#     print(\"Test loss:\", score[0])\n",
    "#     print(\"Test accuracy:\", score[1])\n",
    "#     print(\"Training Time:\", end_time - start_time)\n",
    "\n",
    "# keras_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a71081-46fc-45a8-93b5-95cf437b0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(train_images, test_images), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(10)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=(28, 28, 1),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "        print(f\"action space: {self.action_space}\")\n",
    "        print(f\"observation space: {self.observation_space}\")\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        \n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1e91bcf-e494-4ea3-86b4-224b46020666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Discrete(10)\n",
      "observation space: Box(28, 28, 1)\n",
      "DQN Training Time: 0.06399655342102051\n"
     ]
    }
   ],
   "source": [
    "def mnist_dqn():\n",
    "\n",
    "    env = MnistEnv(images_per_episode=1)\n",
    "#     replay_buffer = ReplayBuffer(max_size=1000000)  # Create a replay buffer\n",
    "    env = Monitor(env)\n",
    "    \n",
    "    model = DQN(\"MlpPolicy\",\n",
    "                env,\n",
    "#                 learning_rate=0.0001,\n",
    "                buffer_size=10000,\n",
    "                learning_starts=5,\n",
    "                batch_size=32,\n",
    "#                 tau=1.0,\n",
    "#                 gamma=0.99,\n",
    "#                 train_freq=4,\n",
    "#                 gradient_steps=1,\n",
    "#                 replay_buffer_class=None,\n",
    "#                 replay_buffer_kwargs=None,\n",
    "#                 optimize_memory_usage=False,\n",
    "#                 target_update_interval=10000,\n",
    "#                 exploration_fraction=0.1,\n",
    "#                 exploration_initial_eps=1.0,\n",
    "#                 exploration_final_eps=0.05,\n",
    "#                 max_grad_norm=10,\n",
    "#                 stats_window_size=100,\n",
    "#                 tensorboard_log=None,\n",
    "#                 policy_kwargs=None,\n",
    "#                 verbose=0,\n",
    "#                 seed=None,\n",
    "#                 device='auto',\n",
    "#                 _init_setup_model=True\n",
    "               )\n",
    "    \n",
    "#     model.learn(total_timesteps=10000, log_interval=4)    \n",
    "    model.save('dqn.pkl')\n",
    "    env.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = mnist_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70260cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dqn_eval(dqn_model):\n",
    "#     attempts, correct = 0,0\n",
    "\n",
    "#     env = MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             obs, done = env.reset(), False\n",
    "#             while not done:\n",
    "#                 obs, rew, done, _ = env.step(dqn_model(obs[None])[0])\n",
    "\n",
    "#                 attempts += 1\n",
    "#                 if rew > 0:\n",
    "#                     correct += 1\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print()\n",
    "#         print('validation done...')\n",
    "#         print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "# mnist_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b3ceafd-d4a7-4785-9c41-259a477a642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (8348, 28, 28, 1)\n",
      "8348 train_images samples\n",
      "\n",
      "------------\n",
      "<class 'numpy.ndarray'> 83484\n",
      "<class 'numpy.ndarray'> 1000\n",
      "action space: Discrete(10)\n",
      "observation space: Box(28, 28, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation done...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat((\u001b[38;5;28mfloat\u001b[39m(correct) \u001b[38;5;241m/\u001b[39m attempts) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmnist_dqn_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdqn_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [58], line 18\u001b[0m, in \u001b[0;36mmnist_dqn_eval\u001b[1;34m(dqn_model)\u001b[0m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [21], line 33\u001b[0m, in \u001b[0;36mMnistEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 33\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "Cell \u001b[1;32mIn [21], line 44\u001b[0m, in \u001b[0;36mMnistEnv._next_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx]\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "def mnist_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "#     print(f\"train: {y_train_one_hot.shape}\")\n",
    "#     print(f\"test: {y_test_one_hot.shape}\")\n",
    "\n",
    "#     print(type(y_train_one_hot), len(y_train_one_hot)) \n",
    "#     print(type(y_test_one_hot), len(y_test_one_hot)) \n",
    "    \n",
    "    print(\"train_images shape:\", train_images.shape)\n",
    "    print(train_images.shape[0], \"train_images samples\")\n",
    "    print(\"\\n------------\")\n",
    "    print(type(train_labels), len(train_labels)) \n",
    "    print(type(test_labels), len(test_labels))\n",
    "    env = MnistEnv(images_per_episode=1, dataset=(train_images, test_images), random=False)\n",
    "    model = DQN.load(\"dqn.pkl\")\n",
    "    \n",
    "    try:\n",
    "        obs = env.reset()\n",
    "        while True:\n",
    "            pass\n",
    "#             \n",
    "#             while not done:\n",
    "#               obs, rew, done, _ = env.step(dqn_model(obs[None])[0])\n",
    "                \n",
    "            action, _states = model.predict(obs,\n",
    "                                            deterministic=True)\n",
    "\n",
    "\n",
    "\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            if terminated or truncated:\n",
    "                obs = env.reset()\n",
    "\n",
    "            attempts += 1\n",
    "            if rew > 0:\n",
    "                correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_dqn_eval(dqn_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dqn_eval(dqn_model):\n",
    "#     attempts, correct = 0,0\n",
    "#     print(f\"train: {train_labels.shape}\")\n",
    "#     print(f\"test: {test_labels.shape}\")                           \n",
    "#     env = MnistEnv(images_per_episode=1, dataset=(train_labels, test_labels), random=False)\n",
    "    \n",
    "#     model = DQN.load(\"dqn.pkl\")\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         obs = env.reset()\n",
    "#         while True:\n",
    "#             action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             obs, reward, terminated, truncated, info = env.step(action)\n",
    "#             if terminated or truncated:\n",
    "#                 obs, info = env.reset()\n",
    "\n",
    "#             attempts += 1\n",
    "#             if reward > 0:\n",
    "#                 correct += 1\n",
    "\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print()\n",
    "#         print('validation done...')\n",
    "#         print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "# mnist_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0fa87-bcb2-4010-81f5-2f3896209b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_ppo():\n",
    "#     logger.configure(dir='./logs/mnist_ppo', format_strs=['stdout', 'tensorboard'])\n",
    "#     env = DummyVecEnv([lambda: bench.Monitor(MnistEnv(images_per_episode=1), logger.get_dir())])\n",
    "\n",
    "#     model = ppo2.learn(\n",
    "#         env=env,\n",
    "#         network='mlp',\n",
    "#         num_layers=2,\n",
    "#         num_hidden=64,\n",
    "#         nsteps=32,\n",
    "#         total_timesteps=int(1.2e5),\n",
    "#         seed=int(time.time()))\n",
    "\n",
    "#     return model\n",
    "\n",
    "# start_time = time.time()\n",
    "# ppo_model = mnist_ppo()\n",
    "# print(\"PPO Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c1250-43fa-4da5-bf51-c2ca1c584e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_ppo_eval(ppo_model):\n",
    "#     attempts, correct = 0,0\n",
    "\n",
    "#     env = DummyVecEnv([lambda: MnistEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)])\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             obs, done = env.reset(), [False]\n",
    "#             while not done[0]:\n",
    "#                 obs, rew, done, _ = env.step(ppo_model.step(obs[None])[0])\n",
    "\n",
    "#                 attempts += 1\n",
    "#                 if rew[0] > 0:\n",
    "#                     correct += 1\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print()\n",
    "#         print('validation done...')\n",
    "#         print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "# mnist_ppo_eval(ppo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4885655-529e-4f1c-9bbd-1a6aadfb6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Discrete(10)\n",
      "observation space: Box(28, 28, 1)\n",
      "DQN Training Time: 0.050980567932128906\n",
      "train: (83484,)\n",
      "test: (1000,)\n",
      "action space: Discrete(10)\n",
      "observation space: Box(28, 28, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation done...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat((\u001b[38;5;28mfloat\u001b[39m(correct) \u001b[38;5;241m/\u001b[39m attempts) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmnist_dqn_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdqn_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [39], line 37\u001b[0m, in \u001b[0;36mmnist_dqn_eval\u001b[1;34m(dqn_model)\u001b[0m\n\u001b[0;32m     34\u001b[0m env \u001b[38;5;241m=\u001b[39m MnistEnv(images_per_episode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dataset\u001b[38;5;241m=\u001b[39m(train_images, test_images), random\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         action, _states \u001b[38;5;241m=\u001b[39m dqn_model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [21], line 33\u001b[0m, in \u001b[0;36mMnistEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 33\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "Cell \u001b[1;32mIn [21], line 44\u001b[0m, in \u001b[0;36mMnistEnv._next_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx]\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Define MnistEnv and other classes if not defined in your code\n",
    "# ...\n",
    "\n",
    "def mnist_dqn():\n",
    "    env = MnistEnv(images_per_episode=1)\n",
    "    env = Monitor(env)\n",
    "    \n",
    "    model = DQN(\"MlpPolicy\",\n",
    "                env,\n",
    "                buffer_size=10000,\n",
    "                learning_starts=5,\n",
    "                batch_size=32,\n",
    "               )\n",
    "    \n",
    "    model.save('dqn.pkl')\n",
    "    env.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = mnist_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)\n",
    "\n",
    "def mnist_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0, 0\n",
    "    print(f\"train: {train_labels.shape}\")\n",
    "    print(f\"test: {test_labels.shape}\")                           \n",
    "    env = MnistEnv(images_per_episode=1, dataset=(train_labels, test_labels), random=False)\n",
    "    \n",
    "    try:\n",
    "        obs = env.reset()\n",
    "        while True:\n",
    "            action, _states = dqn_model.predict(obs, deterministic=True)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            if terminated or truncated:\n",
    "                obs, info = env.reset()\n",
    "\n",
    "            attempts += 1\n",
    "            if reward > 0:\n",
    "                correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "mnist_dqn_eval(dqn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925ab82-baf5-4f6c-a5ca-b8035e32dea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f42b1-2768-47d6-866b-1c7a153be042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffb317-15ed-4870-b015-a1356693c4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5eb13-3d6d-449f-8736-808d4c1c176b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e19e0-ad86-4625-8e9b-e2897a21e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "print(type(x_test.shape[0]), \"type\")\n",
    "print(len(x_test.shape), \"Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7601c-9904-4be1-9c28-2abeaf71eafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e2a88-18fc-411c-aa96-a4a2b8372659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11623f0-f1c6-40ff-bde9-a7b226dc1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31826d0c-bf06-4af7-b366-56bd3cd2197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbd57c-d89b-4f1c-86b7-591cfd8ab455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a6945-e671-4020-8ba3-9e1a55d2b40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00611bb-1a11-4771-af5c-362e3effb025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a686ba-b530-4dcb-963b-b384a301a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4017016-4e97-4fb6-b056-31f81d6d1159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a404-5d71-4b54-9bd9-33b3ab6b12a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df45aa9-9782-4ebe-bc52-0767246f9c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ac9af-f1f0-4fd5-ab45-6fc365df6a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a312b-0ffd-474e-a2e3-857314976a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa8c23-eb95-4f49-93ab-646e8bed4b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234074d8-d5db-44b7-a371-9e9b68ca106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0894e2-dfaf-45e7-8a59-6477dd246fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154de4fc-32b0-4f18-a37e-1a47df690b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fcb2d-1e1a-4b97-8882-673532a72834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40640fa7-ed33-4b31-b432-c8d94be4d9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a6359-5e52-4a87-afda-dd75a8cb9fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
